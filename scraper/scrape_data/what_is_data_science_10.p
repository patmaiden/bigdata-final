(lp0
S'        data science   from wikipedia the free encyclopedia   jump to navigation  search   this articles tone or style may not reflect the encyclopedic tone used on wikipedia  see wikipedias guide to writing better articles for suggestions  february 2014 part of a series on statistics data visualization major dimensions exploratory data analysis  information design descriptive statistics  inferential statistics statistical graphics  plot data analysis  infographic data science thought leaders john w tukey  edward tufte information graphic types line chart  bar chart histogram  scatterplot boxplot  pareto chart pie chart  area chart control chart  run chart stemandleaf display  cartogram small multiple  sparkline table related topics data  information big data  database chartjunk  visual perception regression analysis  statistical model misleading graph v t e in general terms data science is the extraction of knowledge from data   1   2  it employs techniques and theories drawn from many fields within the broad areas of mathematics  statistics  information theory and information technology  including signal processing  probability models  machine learning  statistical learning  computer programming  data engineering  pattern recognition and learning  visualization  predictive analytics  uncertainty modeling  data warehousing  data compression and high performance computing  methods that scale to big data are of particular interest in data science although the discipline is not generally considered to be restricted to such data the development of machine learning  a branch of artificial intelligence used to uncover patterns in data from which predictive models can be developed has enhanced the growth and importance of data science data scientists apply expertise in data preparation statistics and machine learning to investigate complex problems in many various domains such as marketing optimization fraud detection setting public policy etc these areas represent great breadth and diversity of knowledge and a data scientist will most likely be expert in only one or at most two of these areas and merely proficient in the others therefore a data scientist typically works as part of a team whose other members have knowledge and skills which complement his or hers  3  data scientists use the ability to find and interpret rich data sources manage large amounts of data despite hardware software and bandwidth constraints merge data sources ensure consistency of datasets create visualizations to aid in understanding data build mathematical models using the data and present and communicate the data insightsfindings preferably actionable insights to specialists and scientists in their team and if required to a nontechnical audience data science techniques affect research in many domains including the biological sciences  medical informatics  health care  social sciences and the humanities  it heavily influences economics  business and finance  from the business perspective data science is an integral part of competitive intelligence a newly emerging field that encompasses a number of activities such as data mining and data analysis   4  contents 1  history 2  domain specific interests 3  criticism 4  research areas 41  security data science 42  clinical data science 43  genomic data science 5  conferences 6  further reading 7  references history  edit  data science process flowchart the term data science originally used interchangeably with  datalogy  has existed for over thirty years and was used initially as a substitute for computer science by peter naur in 1960 in 1974 naur published concise survey of computer methods  which freely used the term data science in its survey of the contemporary data processing methods that are used in a wide range of applications in 1996 members of the international federation of classification societies ifcs met in kobe for their biennial conference here for the first time the term data science is included in the title of the conference data science classification and related methods  5  in november 1997 cf jeff wu gave the inaugural lecture entitled statistics  data science  6  for his appointment to the h c carver professorship at the university of michigan  7  in this lecture he characterized statistical work as a trilogy of data collection data modeling and analysis and decision making in conclusion he coined the term data science and advocated that statistics be renamed data science and statisticians data scientists  6  later he presented his lecture entitled statistics  data science as the first of his 1998 pc mahalanobis memorial lectures  8  these lectures honor prasanta chandra mahalanobis  an indian scientist and statistician and founder of the indian statistical institute  in 2001 william s cleveland introduced data science as an independent discipline extending the field of statistics to incorporate advances in computing with data in his article data science an action plan for expanding the technical areas of the field of statistics which was published in volume 69 no 1 of the april 2001 edition of the international statistical review  revue internationale de statistique  9  in his report cleveland establishes six technical areas which he believed to encompass the field of data science multidisciplinary investigations models and methods for data computing with data pedagogy tool evaluation and theory in april 2002 the international council for science committee on data for science and technology codata  10  started the data science journal   11  a publication focused on issues such as the description of data systems their publication on the internet applications and legal issues  12  shortly thereafter in january 2003 columbia university began publishing the journal of data science   13  which provided a platform for all data workers to present their views and exchange ideas the journal was largely devoted to the application of statistical methods and quantitative research in 2005 the national science board published longlived digital data collections enabling research and education in the 21st century defining data scientists as the information and computer scientists database and software and programmers disciplinary experts curators and expert annotators librarians archivists and others who are crucial to the successful management of a digital data collection whose primary activity is to conduct creative inquiry and analysis  14  in 2008  citation needed   dj patil and jeff hammerbacher coined the term data scientist to define their jobs at linkedin and facebook respectively  15  domain specific interests  edit  data science is the practice of deriving valuable insights from data data science is emerging to meet the challenges of processing very large data sets ie big data consisting of structured unstructured or semistructured data that large enterprises produce a domain at center stage of data science is the explosion of new data generated from smart devices web mobile and social media data science requires a versatile skillset many practicing data scientists commonly specialize in specific domains such as the fields of marketing medical security fraud and finance however data scientists rely heavily upon elements of statistics  machine learning  optimization  signal processing  text retrieval and natural language processing to analyze data and interpret results criticism  edit  although use of the term data science has exploded in business environments many academics and journalists see no distinction between data science and statistics  writing in forbes  gil press argues that data science is a buzzword without a clear definition and has simply replaced business analytics in contexts such as graduate degree programs  16  in the questionandanswer section of his keynote address at the joint statistical meetings of american statistical association  noted applied statistician nate silver said i think datascientist is a sexed up term for a statisticianstatistics is a branch of science data scientist is slightly redundant in some way and people shouldnt berate the term statistician  17  research areas  edit  as an interdisciplinary subject data science draws scientific inquiry from a broad range of academic subject areas mostly related to the hard sciences some areas of research are cloud computing databases and information integration signal processing learning natural language processing and information extraction computer vision information retrieval and web information access knowledge discovery in social and information networks information visualization security data science  edit  data science has a long and rich history in security and fraud monitoring reference needed  security data science is focused on advancing information security through practical applications of exploratory data analysis statistics machine learning and data visualization although the tools and techniques are no different that those used in data science in any data domain this group has a microfocus on reducing risk identifying fraud or malicious insiders using data science the information security and fraud prevention industry have been evolving security data science in order to tackle the challenges of managing and gaining insights from huge streams of log data discover insider threats and prevent fraud data science companies like feedzai  18  use a mix of big data machine learning and human intelligence to identify fraudulent payment transactions security data science is data driven  meaning that new insights and value comes directly from data  19  clinical data science  edit  data science has always been prominent in the field of clinical trials  timely insight into clinical data provides answers to medical questions documenting the safety and efficacy of novel and existing therapeutic compounds with large and complex data clinical data scientists have been producing statistical analyses of clinical trials for marketing applications since clinical development has been required in the early 2000s the clinical data scientist evolved from a role of a consultant to statisticians to a strategic one now the clinical data scientist assists in the planning collection transformation analysis and reporting of clinical trial data and communication of their results these scientists are crucial to the determination of safety and efficacy of novel therapeutic compounds genomic data science  edit  application of data science does not only stop at clinical trials it was also applied to learning the proteins and dna sequences in genomics  this field because of the tools of the data scientist the work for analyzing and studying dna structures viruses and other biological pathogens handling of data is around before but using data science will make it easier for handling vast amount of data in genomics and make the procedures repeatable conferences  edit  dataedge conference data education a new generation of datasavvy professionals held by school of information uc berkeley google dataedgeischoolberkeleyedu  2012 icdse international conference on data science and engineering held by department of computer science cochin university of science and technology icdsecusatacin  2012 annual international workshop on dataology and data science held by research center on dataology and datascience fudan university china iwddsfudaneducn  2010 2011 2012 data scientist summit held by emc corporation wwwgreenplumcomdatasciencesummit  2011 2012 oreilly strata conference held by oreilly emc microsoft hpcc systems ibm vmware oracle cloudera etc strataconfcom open data science conference on open source languages tools and topics in data science held by ods 1 ieee international conference on big data 2 data science workshops  3  4  2013 the data science conference wwwthedatascienceconferencecom  2015 vendorfree recruiterfree and sponsorfree further reading  edit  jeffrey m stanton 20 may 2012 introduction to data science  syracuse university school of information studies  retrieved 8 august 2012   calvin andrus 2012 data science an introduction  wikibooksorg  retrieved 8 august 2012    20   21   22   23  drew conway john myles white machine learning for hackers oreilly media inc  24   25  jun luke huan theoretic foundation of data science eecs 940  20 may 2012  retrieved 1 january 2012    university of kansas matthew a russell mining the social web 2nd edition oreily media inc  26  references  edit  wikimedia commons has media related to data science  wikibooks has more on the topic of data science   dhar v 2013 data science and prediction  communications of the acm  56 12 64 doi  1011452500499    edit   jeff leek 20131212 the key word in data science is not data it is science  simply statistics    big careers in big data  villanova university     laponsie maryalene data scientists the hottest job you havent heard of  retrieved 7 october 2012     forbesgil pressa very short history of data sciencemay 2013  a  b  wu c f j 1997 statistics  data science  pdf  retrieved 9 october 2014     identity of statistics in science examined  the university records 9 november 1997 the university of michigan  retrieved 12 august 2013     pc mahalanobis memorial lectures 7th series  pc mahalanobis memorial lectures indian statistical institute  retrieved 18 august 2013     cleveland w s 2001 data science an action plan for expanding the technical areas of the field of statistics international statistical review  revue internationale de statistique 2126   international council for science  committee on data for science and technology 2012 april codata the committee on data for science and technology retrieved from international council for science  committee on data for science and technology httpwwwcodataorg   data science journal 2012 april available volumes retrieved from japan science and technology information aggregator electronic httpwwwjstagejstgojpbrowsedsjvols   data science journal 2002 april contents of volume 1 issue 1 april 2002 retrieved from japan science and technology information aggregator electronic httpwwwjstagejstgojpbrowsedsj10contents   the journal of data science 2003 january contents of volume 1 issue 1 january 2003 retrieved from httpwwwjdsonlinecomv11   national science board longlived digital data collections enabling research and education in the 21st century  national science foundation  retrieved 30 june 2013     tim oreilly the worlds 7 most powerful data scientists httpwwwforbescompictureslmm45emkh2jeffhammerbacherchiefscientistclouderaanddjpatilentrepreneurinresidencegreylockventures    missing or empty url  help    data science whats the halflife of a buzzword  forbes  20130819    nate silver what i need from statisticians  statistics views  23 aug 2013    feedzai  wikipedia  wikipedia  retrieved 19 june 2014     httpwwwsecuritydatascienceorg   anderson janna the future of the internet  pdf  pew research center  retrieved 7 october 2012     west darrell big data for education data mining data analytics and web dashboards  pdf  the brookings institution  retrieved 7 october 2012     davenport thomas the human side of big data and highperformance analytics  pdf  international institute for analytics  retrieved 7 october 2012     hellerstein joseph the madlib analytics library or mad skills the sql  pdf  university of california at berkeley  retrieved 7 october 2012     stodder david customer analytics in the age of social media  pdf  tdwi research  retrieved 7 october 2012     yangyong zhu yun xiong june 2011 dataology and data scienceup to now     loukides mike mining the social web again  retrieved 21 mar 2014    oreilly radar    img srcenwikipediaorgwikispecialcentralautologinstarttype1x1 alt title width1 height1 styleborder none position absolute   retrieved from  httpenwikipediaorgwindexphptitledatascienceoldid660580427   categories  information science computer occupations hidden categories pages using web citations with no url use dmy dates from december 2012 wikipedia articles needing style editing from february 2014 all articles needing style editing all articles with unsourced statements articles with unsourced statements from july 2014 commons category with local link same as on wikidata      navigation menu    personal tools   create account log in      namespaces   article  talk     variants          views   read  edit  view history     more         search              navigation    main page  contents  featured content  current events  random article  donate to wikipedia  wikipedia store      interaction    help  about wikipedia  community portal  recent changes  contact page      tools    what links here  related changes  upload file  special pages  permanent link  page information  wikidata item  cite this page      printexport    create a book  download as pdf  printable version      languages    deutsch    francais    latviesu    polski    simple english      edit links        this page was last modified on 3 may 2015 at 1238  text is available under the creative commons attributionsharealike license additional terms may apply  by using this site you agree to the terms of use and privacy policy  wikipedia is a registered trademark of the wikimedia foundation inc  a nonprofit organization    privacy policy  about wikipedia  disclaimers  contact wikipedia  developers  mobile view             '
p1
aS'    skip to main content             about  overview  about the uc berkeley school of information   about dean saxenian   about mids faculty  what is data science   which degree program is right for you   in the news  2u our program partner admissions  admissions overview  admissions requirements  datascienceberkeley class profile  tuition and financial aid   sponsorship tips   online information sessions  faq academics  overview  curriculum   course schedule   immersion   november 2014  may 2014  experience  overview  online learning  student profiles  student support  career services blog apply                855678mids          datascienceberkeley  about  what is data science     the current page is overview    the current page is about the uc berkeley school of information    the current page is about mids faculty    the current page is what is data science   which degree program is right for you   the current page is in the news    the current page is 2u our program partner         this link opens in a new window      this link opens in a new window      this link opens in a new window      this link opens in a new window      this link opens in a new window                 what is data science  a new field emerges there is significant and growing demand for datasavvy professionals in businesses public agencies and nonprofits the supply of professionals who can work effectively with data at scale is limited and is reflected by rapidly rising salaries for data engineers data scientists statisticians and data analysts a recent study by the mckinsey global institute concludes a shortage of the analytical and managerial talent necessary to make the most of big data is a significant and pressing challenge for the us the report estimates that there will be four to five million jobs in the us requiring data analysis skills by 2018 and that large numbers of positions will only be filled through training or retraining the authors also project a need for 15 million more managers and analysts with deep analytical and technical skills who can ask the right questions and consume the results of analysis of big data effectively the statistics listed below represent this significant and growing demand for data scientists 15 highest paying job in demand 3433 number of job openings 105395 average base salary 9 best job in america for 2015 sources httpwwwglassdoorcomblogjobsamerica and httpwwwglassdoorcombloghighestpayingjobsdemand an explosion of data data is increasingly cheap and ubiquitous we are now digitizing analog content that was created over centuries and collecting myriad new types of data from web logs mobile devices sensors instruments and transactions ibm estimates that 90 percent of the data in the world today has been created in the past two years at the same time new technologies are emerging to organize and make sense of this avalanche of data we can now identify patterns and regularities in data of all sorts that allow us to advance scholarship improve the human condition and create commercial and social value the rise of big data has the potential to deepen our understanding of phenomena ranging from physical and biological systems to human social and economic behavior  a challenge identified virtually every sector of the economy now has access to more data than would have been imaginable even a decade ago businesses today are accumulating new data at a rate that exceeds their capacity to extract value from it the question facing every organization that wants to attract a community is how to use data effectively  not just their own data but all of the data thats available and relevant this hot new field promises to revolutionize industries from business to government health care to academia  the new york times our ability to derive social and economic value from the newly available data is limited by the lack of expertise working with this data requires distinctive new skills and tools the corpuses are often too voluminous to fit on a single computer to manipulate with traditional databases or statistical tools or to represent using standard graphics software the data is also more heterogeneous than the highly curated data of the past digitized text audio and visual content like sensor and weblog data is typically messy incomplete and unstructured it is often of uncertain provenance and quality and frequently must be combined with other data to be useful working with usergenerated data sets also raises challenging issues of privacy security and ethics the field of data science is emerging at the intersection of the fields of social science and statistics information and computer science and design the uc berkeley school of information is ideally positioned to bring these disciplines together and to provide students with the research and professional skills to succeed in leading edge organizations learn more  there is no agreed upon definition for big data the tools of data science are as appropriate for gigabyte as they are for petabyte scale datasets big data typically refers to data on the scale of terabytes 10 to the 12th power and petabytes 10 to the 15th power a petabyte is a million gigabytes                             about  admissions  academics  blog  legal  site map        university of california berkeley 102 south hall 4600 berkeley ca 947204600 ischoolberkeleyedu   phone 855678mids   admissionsdatascienceberkeleyedu          2015                                                    uc berkeley school of information   phone 855678mids     admissionsdatascienceberkeleyedu               '
p2
aS'  this page may be out of date save your draft before refreshing this page submit any pending changes before refreshing this page hide this message  quora  login sign up share question twitter facebook google related topics information data data science what is data science want answers 500   27 answers   michael hochster  statistician statistician 308  upvotes by  yair livne   justin rising   mahesh srinivasan  more loading data scientists are people with some mix of coding and statistical skills who work on making data useful in various ways in my world there are two main types type a data scientist the a is for analysis this type is primarily concerned with making sense of data or working with it in a fairly static waythe type a data scientist is very similar to a statistician and may be one but knows all the practical details of working with data that arent taught in the statistics curriculum  data cleaning methods for dealing with very large data sets visualization deep knowledge of a particular domain writing well about data and so on the type a data scientist can code well enough to work with data but is not necessarily an expert the type a data scientist may be an expert in experimental design forecasting modeling statistical inference or other things typically taught in statistics departments generally speaking though the work product of a data scientist is not pvalues and confidence intervals as academic statistics sometimes seems to suggest and as it sometimes is for traditional statisticians working in the pharmaceutical industry for example at google type a data scientists are known variously as statistician quantitative analyst decision support engineering analyst or data scientist and probably a few more type b data scientist the b is for building type b data scientists share some statistical background with type a but they are also very strong coders and may be trained software engineers  the type b data scientist is mainly interested in using data in production  they build models which interact with users often serving recommendations products people you may know ads movies search results at google a type b data scientist would typically be called a software engineer type b data scientists may use the term data scientist to refer just to themselves and since the definition of the field is very much in flux they may be right but i see the term being used most often in the general way i am proposing here this categorization is crude many data scientists are some mix of a and b but this answer is long enough already embed quote written 16 jan 2014  20349 views  asked to answer by  william chen  upvote 308 downvote comments 4  more answers below related questions  what is the data science topic faq  how do i become a data scientist will data science be commoditized who are the women in data science what is your data science pipelineworkflow  michael e driscoll  i  data analytics  visualization i  data analytics  visualization 112  upvotes by  peter skomoroch   drew conway   roger ehrenberg  more loading data science as its practiced is a blend of redbullfueled hacking and espressoinspired statistics but data science is not merely hacking because when hackers finish debugging their bash oneliners and pig scripts few care about noneuclidean distance metrics and data science is not merely statistics because when statisticians finish theorizing the perfect model few could read a a delimited file into r if their job depended on it data science is the civil engineering of data  its acolytes possess a practical knowledge of tools  materials coupled with a theoretical understanding of whats possible some worthwhile articles on the topic elsewhere the data science venn diagram   drew conway   httpwwwdataistscom2 01009 the rise of the data scientist  nathan yau   httpflowingdatacom20 09060 the three sexy skills of data geeks yours truly  httpwwwdatasporacom blogse finally its worth noting  the job title data scientist came into its recent vogue when quora user coined the term at facebook in 2007 embed quote updated 15 feb 2011  20160 views  upvote 112 downvote comments 1   drew conway  phd student in politics at nyu study  more  phd student in politics at nyu studying networks terrorism conflict and technology 74  upvotes by anonymous   ian wong   xian xu  more loading first the term data science is a misnomer with respect to what most people consider endeavors classified as such  fundamentally science is about formalizing a hypothesis given a reasonable set of observations and assumptions designing an experiment around that hypothesis testings it and analyzing the data generated through that process to either confirm or falsify the hypothesis  therefore data is simply a natural byproduct of science  very very rarely are things labeled as data science actually scientific rather data science most often refers to the tools and methods used to analyze large amounts of data  as such the discipline is an amalgamation of many bits from other areas of research  for tools the influence primarily comes from computer science where issues of algorithmic efficiency and storage scalability form the main focus  for analysis however the influences are much more varied modern methods are borrowed from both the socalled hard sciences physics statistics graph theory and the social sciences economics sociology political sciences etc  specific classes of techniques that are naturally interdisciplinary are also very popular such as machine learning mike loukides had an interesting article in oreilly that posited the same question and is worth a read httpradaroreillycom 201006 embed quote written 22 aug 2010  20334 views  upvote 74 downvote comments 2  quora user  data scientist data scientist 33  upvotes by  david toyli   mert kilickaya   tariq alsadoon  more loading i have been a data scientist for about two years here are some quick thoughts on what i think data science is or why dont we start with what data science is not first data science is not a software engineering piece of work that is data science is not about building products or product features or systems or any related fancy things second data science is not a visualization piece of work creating the cool visual is neither the end goal nor the beginning part of how a data scientist works needless to say data science is not about creating visually impactful infographics third data science is not a scientific piece of work in particular data scientists dont work in the academia it is the industrys particular requirements and the business markets call that makes the job of data scientist needed data scientists usually dont publish papers and neither is the paper or book publishing business part of any data scientists daily concerns last but not least i dont agree with the public view that data science is at least mostly statistics just to cite a quick story of myself once i was asked to hire someone to assist my work and ended up interviewing lots of applicants through phone many of the applicants came from the filed of statistical analysis and most of these applicants tended to sound really confident that he or she would be more than qualified for the role however i didnt end up calling any of them onsite one thing i realized at that time was that statistical knowledge alone doesnt make a person qualified for assisting me effectively on the kind of data science work that i needed to do for reasons ill mention in a short while now we are ready to talk about what data science is its a thing that encapsulates some programming skills some statistical readiness some visualization techniques and last but not least a lot of business senses the kind of business sense that i in particular care about is the ability and willingness sometimes eagerness to translate any business questions into questions answerable using currently or forthcomingly available data within ones reach in fact it takes a special way of connecting all the dots in the random world full of data most of which you may not find immediately useful to make a working data scientist a data scientist based on my current understanding is the person who connects the dots between the business world and the data world similarly data science is the craft that a data scientist utilizes to make this happen im going to share a favorite analogue of mine about data science doing data science is like preparing a meal one starts with data munging which includes but is not restricted to etl extract transform and load data cleansing data debugging etc this is the step similar to preparing the food source where you rinse cleans the vegetables the meat and the rice chop the food source into reasonably sized pieces and put them aside after that is done you are ready to cook the food source which corresponds to data exploration feature construction feature reduction running and ensembling the algorithms etc this is when you cook the vegetable and meat in a stepbystep fashion adding ingredients and sources on particularly calculated timing and watching the raw material turn into edible pieces the last step is to serve the food when you arrange the cooked food in artistic ways and serve them in a particular sequence of first course second course etc to customers who ordered the food to begin with this is when you prepare your data mining results in artistic visualization and create reports or data stories to send to the business users who wanted this piece of data science work to be done on the first place summarizing the above the process of data science consists of data munging data mining and delivering actionable insights based on my own experience a common toolset to get all or part of these done include python r tableau sql etc python is particularly handy as an allpurpose tool especially great for data munging it can also be used for data mining thanks to the almighty scikitlearn package and even insight delivering based on its fast growing graphing abilities r is a bit shy on data munging compared to python however because of its nature of being statistically complete  a word i just made up meaning that any statistical thingie you have ever heard of is most likely already represented by a r package or two  r is great for exploring the data and running algorithms on different parameter settings this makes r a great tool for prototyping data science  for example to identify the key feature set as well as a good enough machine learning algorithm with parameter setting before you start to write complicated production code for real in addition to the above r is also powerful with its visualization packages and can be used to turn a repeatable data mining piece into a shiny report talking about data visualization tableau is one of the best commercial software for visually explore your data it is also handy for creating interactive visualization reports or data stories besides python r tableau theres one more data science tool that i want to mention before finishing this post sql is the language of english in the world of data munging or at least have been so for a very long time it is powerful in integrating different data sources and handy for data exploration and data debugging these are just my two cents on what data science is i hope it make sense to you so far im still a learner and merely a beginner in this field and i expect to pick up a lot more and deeper understanding on this subject matter in the near future embed quote updated 22 mar  1604 views  upvote 33 downvote comments 2   shlomo argamon  director of the master of data scienc  more  director of the master of data science program at illinois institute of technology 30  upvotes by  amar parkash   justin rising   toma shazly  more loading data science is a real thing it is more than just a collection of tools and methods for analyzing large and complex data sets more than just collaboration between computer scientists and statisticians and far more than just a fancy term for statistics in san francisco or the like at its core data science is about making sense of the world using data this involves the use of various tools for data cleaning structuring querying analysis visualization and the like involves statistical modeling to some extent often involves building new computational tools involves figuring out the right relevant questions to ask the data and how to explain what the data say and dont say and critically involves application of the scientific method to ensure that results are solid and properly understood hence the word science in the name in a sense this is a new word for work that scientists and statisticians have done for a long time but the new abundance of data that carry information about virtually everything together with the availability of tools computational and statistical to work with the data makes the task of empirical sensemaking ie data science more broadly applicable and more important than before embed quote written 17 jul 2014  3762 views  upvote 30 downvote comments 1  more write an answer related questions what is the future of data science is data science a fad  what are the best blogs about data which companies have the best data science teams  what is it like to design a data science class open science   how can we encourage scientists to store their raw data in public what are problems with bigdata what is the quantdata science career ladder at google reviews of the open source data science masters what classes should i take if i want to become a data scientist  data science   what are some good toy problems in data science reviews of harvard data science certificate reviews of insight data science fellows program data science   how is the data science handbook different from data scientists at work  data science   what are the proven ways to test the analytics literacy of a candidate related questions  what is the data science topic faq  how do i become a data scientist will data science be commoditized who are the women in data science what is your data science pipelineworkflow what is the future of data science is data science a fad  what are the best blogs about data which companies have the best data science teams  what is it like to design a data science class                 top stories sitemap  a b c d e f g h i j k l m n o p q r s t u v w x y z about  careers  privacy  terms'
p3
aS'  select a countryregion united states  ibm site map  search hadoop what is a data scientist primary tab navigation home what is hadoop data scientist products resources trials  all hadoop terms avro big sql bigsheets data scientist flume hbase hdfs hive mapreduce oozie pig zookeeper     about data scientists  rising alongside the relatively new technology of big data is the new job title data scientist while not tied exclusively to big data projects the data scientist role does complement them because of the increased breadth and depth of data being examined as compared to traditional roles  so what does a data scientist do  a data scientist represents an evolution from the business or data analyst role the formal training is similar with a solid foundation typically in computer science and applications modeling statistics analytics and math what sets the data scientist apart is strong business acumen coupled with the ability to communicate findings to both business and it leaders in a way that can influence how an organization approaches a business challenge good data scientists will not just address business problems they will pick the right problems that have the most value to the organization  the data scientist role has been described as part analyst part artist anjul bhambhri vice president of big data products at ibm says a data scientist is somebody who is inquisitive who can stare at data and spot trends its almost like a renaissance individual who really wants to learn and bring change to an organization  whereas a traditional data analyst may look only at data from a single source  a crm system for example  a data scientist will most likely explore and examine data from multiple disparate sources the data scientist will sift through all incoming data with the goal of discovering a previously hidden insight which in turn can provide a competitive advantage or address a pressing business problem a data scientist does not simply collect and report on data but also looks at it from many angles determines what it means then recommends ways to apply the data  data scientists are inquisitive exploring asking questions doing what if analysis questioning existing assumptions and processes armed with data and analytical results a toptier data scientist will then communicate informed conclusions and recommendations across an organizations leadership structure  learn more about big data       get started with hadoop for the enterprise     try ibm biginsights now    contact us    twitter youtube linkedin blog facebook googleplus      footer links contact privacy terms of use accessibility '
p4
aS' menu home shop video training  books radar safari books online conferences it courses  certificates      oreillycom      oreilly radar      rss feed  twitter  facebook  google  youtube                              home shop video training  books radar  radar  animals safari books online conferences it courses  certificates      data    more topics  data design emerging tech iot programming web ops  performance web platform          help us test a new look for oreilly visit our beta site                      print     listen            what is data science  the future belongs to the companies and people that turn data into products   by  mike loukides   mikeloukides  mike loukides  june 2 2010                 sections where data comes from working with data at scale making data tell its story data scientists download this free report weve all heard it according to hal varian statistics is the next sexy job  five years ago in what is web 20  tim oreilly said that data is the next intel inside but what does that statement mean why do we suddenly care about statistics and about data in this post i examine the many sides of data science  the technologies the companies and the unique skill sets the web is full of datadriven apps almost any ecommerce application is a datadriven application theres a database behind a web front end and middleware that talks to a number of other databases and data services credit card processing companies banks and so on but merely using data isnt really what we mean by data science a data application acquires its value from the data itself and creates more data as a result its not just an application with data its a data product data science enables the creation of data products one of the earlier data products on the web was the cddb database  the developers of cddb realized that any cd had a unique signature based on the exact length in samples of each track on the cd gracenote built a database of track lengths and coupled it to a database of album metadata track titles artists album titles if youve ever used itunes to rip a cd youve taken advantage of this database before it does anything else itunes reads the length of every track sends it to cddb and gets back the track titles if you have a cd thats not in the database including a cd youve made yourself you can create an entry for an unknown album while this sounds simple enough its revolutionary cddb views music as data not as audio and creates new value in doing so their business is fundamentally different from selling music sharing music or analyzing musical tastes though these can also be data products cddb arises entirely from viewing a musical problem as a data problem google is a master at creating data products heres a few examples googles breakthrough was realizing that a search engine could use input other than the text on the page googles pagerank algorithm was among the first to use data outside of the page itself in particular the number of links pointing to a page tracking links made google searches much more useful and pagerank has been a key ingredient to the companys success spell checking isnt a terribly difficult problem but by suggesting corrections to misspelled searches and observing what the user clicks in response google made it much more accurate theyve built a dictionary of common misspellings their corrections and the contexts in which they occur speech recognition has always been a hard problem and it remains difficult but google has made huge strides by using the voice data theyve collected and has been able to integrate voice search into their core search engine during the swine flu epidemic of 2009 google was able to track the progress of the epidemic by following searches for flurelated topics  flu trends google was able to spot trends in the swine flu epidemic roughly two weeks before the center for disease control by analyzing searches that people were making in different regions of the country google isnt the only company that knows how to use data facebook and linkedin use patterns of friendship relationships to suggest other people you may know or should know with sometimes frightening accuracy amazon saves your searches correlates what you search for with what other users search for and uses it to create surprisingly appropriate recommendations these recommendations are data products that help to drive amazons more traditional retail business they come about because amazon understands that a book isnt just a book a camera isnt just a camera and a customer isnt just a customer customers generate a trail of data exhaust that can be mined and put to use and a camera is a cloud of data that can be correlated with the customers behavior the data they leave every time they visit the site the thread that ties most of these applications together is that data collected from users provides added value whether that data is search terms voice samples or product reviews the users are in a feedback loop in which they contribute to the products they use thats the beginning of data science in the last few years there has been an explosion in the amount of data thats available whether were talking about web server logs tweet streams online transaction records citizen science data from sensors government data or some other source the problem isnt finding data its figuring out what to do with it and its not just companies using their own data or the data contributed by their users its increasingly common to mashup data from a number of sources data mashups in r analyzes mortgage foreclosures in philadelphia county by taking a public report from the county sheriffs office extracting addresses and using yahoo to convert the addresses to latitude and longitude then using the geographical data to place the foreclosures on a map another data source and group them by neighborhood valuation neighborhood percapita income and other socioeconomic factors the question facing every company today every startup every nonprofit every project site that wants to attract a community is how to use data effectively  not just their own data but all the data thats available and relevant using data effectively requires something different from traditional statistics where actuaries in business suits perform arcane but fairly welldefined kinds of analysis what differentiates data science from statistics is that data science is a holistic approach were increasingly finding data in the wild and data scientists are involved with gathering data massaging it into a tractable form making it tell its story and presenting that story to others to get a sense for what skills are required lets look at the data lifecycle where it comes from how you use it and where it goes where data comes from data is everywhere your government your web server your business partners even your body  while we arent drowning in a sea of data were finding that almost everything can or has been instrumented at oreilly we frequently combine publishing industry data from nielsen bookscan with our own sales data publicly available amazon data and even job data to see whats happening in the publishing industry sites like infochimps and factual provide access to many large datasets including climate data myspace activity streams and game logs from sporting events factual enlists users to update and improve its datasets which cover topics as diverse as endocrinologists to hiking trails 1956 disk drive one of the first commercial disk drives from ibm it has a 5 mb capacity and its stored in a cabinet roughly the size of a luxury refrigerator in contrast a 32 gb microsd card measures around 58 x 38 inch and weighs about 05 gram photo mike loukides disk drive on display at ibm almaden research much of the data we currently work with is the direct consequence of web 20 and of moores law applied to data the web has people spending more time online and leaving a trail of data wherever they go mobile applications leave an even richer data trail since many of them are annotated with geolocation or involve video or audio all of which can be mined pointofsale devices and frequentshoppers cards make it possible to capture all of your retail transactions not just the ones you make online all of this data would be useless if we couldnt store it and thats where moores law comes in since the early 80s processor speed has increased from 10 mhz to 36 ghz  an increase of 360 not counting increases in word length and number of cores but weve seen much bigger increases in storage capacity on every level ram has moved from 1000mb to roughly 25gb  a price reduction of about 40000 to say nothing of the reduction in size and increase in speed hitachi made the first gigabyte disk drives in 1982 weighing in at roughly 250 pounds now terabyte drives are consumer equipment and a 32 gb microsd card weighs about half a gram whether you look at bits per gram bits per dollar or raw capacity storage has more than kept pace with the increase of cpu speed the importance of moores law as applied to data isnt just geek pyrotechnics data expands to fill the space you have to store it the more storage is available the more data you will find to put into it the data exhaust you leave behind whenever you surf the web friend someone on facebook or make a purchase in your local supermarket is all carefully collected and analyzed increased storage capacity demands increased sophistication in the analysis and use of that data thats the foundation of data science so how do we make that data useful the first step of any data analysis project is data conditioning or getting data into a state where its usable we are seeing more data in formats that are easier to consume atom data feeds web services microformats and other newer technologies provide data in formats thats directly machineconsumable but oldstyle screen scraping hasnt died and isnt going to die many sources of wild data are extremely messy they arent wellbehaved xml files with all the metadata nicely in place the foreclosure data used in data mashups in r was posted on a public website by the philadelphia county sheriffs office this data was presented as an html file that was probably generated automatically from a spreadsheet if youve ever seen the html thats generated by excel you know thats going to be fun to process data conditioning can involve cleaning up messy html with tools like beautiful soup  natural language processing to parse plain text in english and other languages or even getting humans to do the dirty work youre likely to be dealing with an array of data sources all in different forms it would be nice if there was a standard set of tools to do the job but there isnt to do data conditioning you have to be ready for whatever comes and be willing to use anything from ancient unix utilities such as awk to xml parsers and machine learning libraries scripting languages such as perl and python  are essential once youve parsed the data you can start thinking about the quality of your data data is frequently missing or incongruous if data is missing do you simply ignore the missing points that isnt always possible if data is incongruous do you decide that something is wrong with badly behaved data after all equipment fails or that the incongruous data is telling its own story which may be more interesting its reported that the discovery of ozone layer depletion was delayed because automated data collection tools discarded readings that were too low  1  in data science what you have is frequently all youre going to get its usually impossible to get better data and you have no alternative but to work with the data at hand if the problem involves human language understanding the data adds another dimension to the problem roger magoulas who runs the data analysis group at oreilly was recently searching a database for apple job listings requiring geolocation skills while that sounds like a simple task the trick was disambiguating apple from many job postings in the growing apple industry to do it well you need to understand the grammatical structure of a job posting you need to be able to parse the english and that problem is showing up more and more frequently try using google trends to figure out whats happening with the cassandra database or the python language and youll get a sense of the problem google has indexed many many websites about large snakes disambiguation is never an easy task but tools like the natural language toolkit library can make it simpler when natural language processing fails you can replace artificial intelligence with human intelligence thats where services like amazons mechanical turk come in if you can split your task up into a large number of subtasks that are easily described you can use mechanical turks marketplace for cheap labor for example if youre looking at job listings and want to know which originated with apple you can have real people do the classification for roughly 001 each if you have already reduced the set to 10000 postings with the word apple paying humans 001 to classify them only costs 100 working with data at scale weve all heard a lot about big data but big is really a red herring oil companies telecommunications companies and other datacentric industries have had huge datasets for a long time and as storage capacity continues to expand todays big is certainly tomorrows medium and next weeks small the most meaningful definition ive heard big data is when the size of the data itself becomes part of the problem  were discussing data problems ranging from gigabytes to petabytes of data at some point traditional techniques for working with data run out of steam what are we trying to do with data thats different according to jeff hammerbacher 2  hackingdata  were trying to build information platforms or dataspaces information platforms are similar to traditional data warehouses but different they expose rich apis and are designed for exploring and understanding the data rather than for traditional analysis and reporting they accept all data formats including the most messy and their schemas evolve as the understanding of the data changes most of the organizations that have built data platforms have found it necessary to go beyond the relational database model traditional relational database systems stop being effective at this scale managing sharding and replication across a horde of database servers is difficult and slow the need to define a schema in advance conflicts with reality of multiple unstructured data sources in which you may not know whats important until after youve analyzed the data relational databases are designed for consistency to support complex transactions that can easily be rolled back if any one of a complex set of operations fails while rocksolid consistency is crucial to many applications its not really necessary for the kind of analysis were discussing here do you really care if you have 1010 or 1012 twitter followers precision has an allure but in most datadriven applications outside of finance that allure is deceptive most data analysis is comparative if youre asking whether sales to northern europe are increasing faster than sales to southern europe you arent concerned about the difference between 592 percent annual growth and 593 percent to store huge datasets effectively weve seen a new breed of databases appear these are frequently called nosql databases or nonrelational databases though neither term is very useful they group together fundamentally dissimilar products by telling you what they arent many of these databases are the logical descendants of googles bigtable and amazons dynamo  and are designed to be distributed across many nodes to provide eventual consistency but not absolute consistency and to have very flexible schema while there are two dozen or so products available almost all of them open source a few leaders have established themselves cassandra  developed at facebook in production use at twitter rackspace reddit and other large sites cassandra is designed for high performance reliability and automatic replication it has a very flexible data model a new startup riptano  provides commercial support hbase  part of the apache hadoop project and modelled on googles bigtable suitable for extremely large databases billions of rows millions of columns distributed across thousands of nodes along with hadoop commercial support is provided by cloudera  storing data is only part of building a data platform though data is only useful if you can do something with it and enormous datasets present computational problems google popularized the mapreduce approach which is basically a divideandconquer strategy for distributing an extremely large problem across an extremely large computing cluster in the map stage a programming task is divided into a number of identical subtasks which are then distributed across many processors the intermediate results are then combined by a single reduce task in hindsight mapreduce seems like an obvious solution to googles biggest problem creating large searches its easy to distribute a search across thousands of processors and then combine the results into a single set of answers whats less obvious is that mapreduce has proven to be widely applicable to many large data problems ranging from search to machine learning the most popular open source implementation of mapreduce is the hadoop project  yahoos claim that they had built the worlds largest production hadoop application  with 10000 cores running linux brought it onto center stage many of the key hadoop developers have found a home at cloudera  which provides commercial support amazons elastic mapreduce makes it much easier to put hadoop to work without investing in racks of linux machines by providing preconfigured hadoop images for its ec2 clusters you can allocate and deallocate processors as needed paying only for the time you use them hadoop goes far beyond a simple mapreduce implementation of which there are several its the key component of a data platform it incorporates hdfs  a distributed filesystem designed for the performance and reliability requirements of huge datasets the hbase database hive  which lets developers explore hadoop datasets using sqllike queries a highlevel dataflow language called pig  and other components if anything can be called a onestop information platform hadoop is it hadoop has been instrumental in enabling agile data analysis in software development agile practices are associated with faster product cycles closer interaction between developers and consumers and testing traditional data analysis has been hampered by extremely long turnaround times if you start a calculation it might not finish for hours or even days but hadoop and particularly elastic mapreduce make it easy to build clusters that can perform computations on long datasets quickly faster computations make it easier to test different assumptions different datasets and different algorithms its easer to consult with clients to figure out whether youre asking the right questions and its possible to pursue intriguing possibilities that youd otherwise have to drop for lack of time hadoop is essentially a batch system but hadoop online prototype hop is an experimental project that enables stream processing hadoop processes data as it arrives and delivers intermediate results in near realtime near realtime data analysis enables features like trending topics on sites like twitter  these features only require soft realtime reports on trending topics dont require millisecond accuracy as with the number of followers on twitter a trending topics report only needs to be current to within five minutes  or even an hour according to hilary mason  hmason  data scientist at bitly  its possible to precompute much of the calculation then use one of the experiments in realtime mapreduce to get presentable results machine learning is another essential tool for the data scientist we now expect web and mobile applications to incorporate recommendation engines and building a recommendation engine is a quintessential artificial intelligence problem you dont have to look at many modern web applications to see classification error detection image matching behind google goggles and snaptell  and even face detection  an illadvised mobile application lets you take someones picture with a cell phone and look up that persons identity using photos available online andrew ngs machine learning course is one of the most popular courses in computer science at stanford with hundreds of students  this video is highly recommended  there are many libraries available for machine learning pybrain in python elefant  weka in java and mahout coupled to hadoop google has just announced their prediction api  which exposes their machine learning algorithms for public use via a restful interface for computer vision the opencv library is a defacto standard mechanical turk is also an important part of the toolbox machine learning almost always requires a training set or a significant body of known data with which to develop and tune the application the turk is an excellent way to develop training sets once youve collected your training data perhaps a large collection of public photos from twitter you can have humans classify them inexpensively  possibly sorting them into categories possibly drawing circles around faces cars or whatever interests you its an excellent way to classify a few thousand data points at a cost of a few cents each even a relatively large job only costs a few hundred dollars while i havent stressed traditional statistics building statistical models plays an important role in any data analysis according to mike driscoll  dataspora  statistics is the grammar of data science it is crucial to making data speak coherently weve all heard the joke that eating pickles causes death because everyone who dies has eaten pickles that joke doesnt work if you understand what correlation means more to the point its easy to notice that one advertisement for r in a nutshell generated 2 percent more conversions than another but it takes statistics to know whether this difference is significant or just a random fluctuation data science isnt just about the existence of data or making guesses about what that data might mean its about testing hypotheses and making sure that the conclusions youre drawing from the data are valid statistics plays a role in everything from traditional business intelligence bi to understanding how googles ad auctions work statistics has become a basic skill it isnt superseded by newer techniques from machine learning and other disciplines it complements them while there are many commercial statistical packages the open source r language and its comprehensive package library cran is an essential tool although r is an odd and quirky language particularly to someone with a background in computer science it comes close to providing one stop shopping for most statistical work it has excellent graphics facilities cran includes parsers for many kinds of data and newer extensions extend r into distributed computing if theres a single tool that provides an endtoend solution for statistics work r is it making data tell its story a picture may or may not be worth a thousand words but a picture is certainly worth a thousand numbers the problem with most data analysis algorithms is that they generate a set of numbers to understand what the numbers mean the stories they are really telling you need to generate a graph edward tuftes visual display of quantitative information is the classic for data visualization and a foundational text for anyone practicing data science but thats not really what concerns us here visualization is crucial to each stage of the data scientist according to martin wattenberg  wattenberg  founder of flowing media  visualization is key to data conditioning if you want to find out just how bad your data is try plotting it visualization is also frequently the first step in analysis hilary mason says that when she gets a new data set she starts by making a dozen or more scatter plots trying to get a sense of what might be interesting once youve gotten some hints at what the data might be saying you can follow it up with more detailed analysis there are many packages for plotting and presenting data gnuplot is very effective r incorporates a fairly comprehensive graphics package casey reas and ben frys processing is the state of the art particularly if you need to create animations that show how things change over time at ibms many eyes  many of the visualizations are fullfledged interactive applications nathan yaus flowingdata blog is a great place to look for creative visualizations one of my favorites is this animation of the growth of walmart over time and this is one place where art comes in not just the aesthetics of the visualization itself but how you understand it does it look like the spread of cancer throughout a body or the spread of a flu virus through a population making data tell its story isnt just a matter of presenting results it involves making connections then going back to other data sources to verify them does a successful retail chain spread like an epidemic and if so does that give us new insights into how economies work thats not a question we could even have asked a few years ago there was insufficient computing power the data was all locked up in proprietary sources and the tools for working with the data were insufficient its the kind of question we now ask routinely data scientists data science requires skills ranging from traditional computer science to mathematics to art describing the data science group he put together at facebook possibly the first data science group at a consumeroriented web property jeff hammerbacher said  on any given day a team member could author a multistage processing pipeline in python design a hypothesis test perform a regression analysis over data samples with r design and implement an algorithm for some dataintensive product or service in hadoop or communicate the results of our analyses to other members of the organization 3 where do you find the people this versatile according to dj patil chief scientist at linkedin  dpatil  the best data scientists tend to be hard scientists particularly physicists rather than computer science majors physicists have a strong mathematical background computing skills and come from a discipline in which survival depends on getting the most from the data they have to think about the big picture the big problem when youve just spent a lot of grant money generating data you cant just throw the data out if it isnt as clean as youd like you have to make it tell its story you need some creativity for when the story the data is telling isnt what you think its telling scientists also know how to break large problems up into smaller problems patil described the process of creating the group recommendation feature at linkedin it would have been easy to turn this into a highceremony development project that would take thousands of hours of developer time plus thousands of hours of computing time to do massive correlations across linkedins membership but the process worked quite differently it started out with a relatively small simple program that looked at members profiles and made recommendations accordingly asking things like did you go to cornell then you might like to join the cornell alumni group it then branched out incrementally in addition to looking at profiles linkedins data scientists started looking at events that members attended then at books members had in their libraries the result was a valuable data product that analyzed a huge database  but it was never conceived as such it started small and added value iteratively it was an agile flexible process that built toward its goal incrementally rather than tackling a huge mountain of data all at once this is the heart of what patil calls data jiujitsu  using smaller auxiliary problems to solve a large difficult problem that appears intractable cddb is a great example of data jiujitsu identifying music by analyzing an audio stream directly is a very difficult problem though not unsolvable  see midomi  for example but the cddb staff used data creatively to solve a much more tractable problem that gave them the same result computing a signature based on track lengths and then looking up that signature in a database is trivially simple hiring trends for data science its not easy to get a handle on jobs in data science however data from oreilly research shows a steady yearoveryear increase in hadoop and cassandra job listings which are good proxies for the data science market as a whole this graph shows the increase in cassandra jobs and the companies listing cassandra positions over time entrepreneurship is another piece of the puzzle patils first flippant answer to what kind of person are you looking for when you hire a data scientist was someone you would start a company with thats an important insight were entering the era of products that are built on data we dont yet know what those products are but we do know that the winners will be the people and the companies that find those products hilary mason came to the same conclusion her job as scientist at bitly is really to investigate the data that bitly is generating and find out how to build interesting products from it no one in the nascent data industry is trying to build the 2012 nissan stanza or office 2015 theyre all trying to find new products in addition to being physicists mathematicians programmers and artists theyre entrepreneurs data scientists combine entrepreneurship with patience the willingness to build data products incrementally the ability to explore and the ability to iterate over a solution they are inherently interdiscplinary they can tackle all aspects of a problem from initial data collection and data conditioning to drawing conclusions they can think outside the box to come up with new ways to view the problem or to work with very broadly defined problems heres a lot of data what can you make from it the future belongs to the companies who figure out how to collect and use data successfully google amazon facebook and linkedin have all tapped into their datastreams and made that the core of their success they were the vanguard but newer companies like bitly are following their path whether its mining your personal biology building maps from the shared experience of millions of travellers or studying the urls that people pass to others the next generation of successful businesses will be built around data the part of hal varians quote that nobody remembers says it all  the ability to take data  to be able to understand it to process it to extract value from it to visualize it to communicate it  thats going to be a hugely important skill in the next decades data is indeed the new intel inside  oreilly publications related to data science r in a nutshell a quick and practical reference to learn what is becoming the standard for developing statistical software statistics in a nutshell an introduction and reference for anyone with no previous background in statistics data analysis with open source tools this book shows you how to think about data and the results you want to achieve with it programming collective intelligence learn how to build web applications that mine the data created by people on the internet beautiful data learn from the best data practitioners in the field about how wideranging  and beautiful  working with data can be beautiful visualization this book demonstrates why visualizations are beautiful not only for their aesthetic design but also for elegant layers of detail head first statistics this book teaches statistics through puzzles stories visual aids and realworld examples head first data analysis learn how to collect your data sort the distractions from the truth and find meaningful patterns  1 the nasa article denies this but also says that in 1984 they decided that the low values whch went back to the 70s were real whether humans or software decided to ignore anomalous data it appears that data was ignored 2 information platforms as dataspaces by jeff hammerbacher in beautiful data  3 information platforms as dataspaces by jeff hammerbacher in beautiful data      tags big data  data  data platform  data product  data science  data scientist                      get the oreilly data newsletter  stay informed receive weekly insight from industry insiders               tim oreilly     this is a really important and articulate post mike  i wish id written it im surprised that there are no comments but 123 retweets already  i guess retweets are the new comments       joe     good post definitely where things are going i just wrote about this and related topics over the long weekend httpwwwjoeandmotorboatcom20100531beyondbigdata       robert richards     thanks for this post it might be useful to note that data science has been recognized as a discipline since at least 2001 that one of the first scholars to use data science in the sense used in this post was dr william s cleveland in his 2001 article data science an action plan for expanding the technical areas of the field of statistics httpjmpa8mqep  that people working in this discipline have organized professional associations including codata the international council for science committee on data for science and technology httpwwwcodataorg  that there are conferences devoted to this discipline including the international codata conference httpwwwcodata2010com  and that there are journals that publish data science research including journal of data science httpwwwjdsonlinecom founded in 2003 and data science journal httpjmp9yyh5r founded in 2002       michael f martin     accountants are a kind of data scientist too       andrew walkingshaw     as one of the three founders of timetric  httptimetriccom  all of whom have a background in the physical sciences im biased but we couldnt agree more       alex tolley     good article  i do question the term data science as in data science enables the creation of data products   science is a process for discovering truth or at least discarding falsity  extracting information from data is more like cooking an art i also am a bit skeptical about the fetishizing of big data  certainly sometimes data sets are necessarily large but arguably better data acquired through better questions is preferable  a second best can be data sampling to reduce the analyzable data set to more tractable proportions  mining large data sets to death is very similar to spreadsheetitis that spread quickly in te 1980s once spreadsheets became widely available  nothing wrong with using spreadsheets except that they tended to focus attention on the questions where data that was available rather than the questions that really needed answers       brandyn     in hindsight mapreduce seems like an obvious solution to googles biggest problem creating large searches its easy to distribute a search across thousands of processors and then combine the results into a single set of answers you wouldnt use mapreduce like this in a lowlatency query situation  it is made for high throughput batch processing not quick turn around       joel     and still to date the best tool to mess around with large data sets is sas  been around for ages seems that as the web matures so too does the tool sets and methodologies it uses to extract value       rukmal fernando     great read on the subject of visualization stanfords protovis is also probably worthy of consideration httpvisstanfordeduprotovis ive only started trying it out but protovis is just javascript and svg and thats a big plus for me       kirk     thanks mike terabyte drives are consumer equipment are the cord wood to my campfire i want to know more about how video data is being analyzed does googles new machine transcription service change the game       brian ahier     this is the best post on data i have ever read i am stunned       ken     aw heck i hate to say this mike but data are not data is but despite my nitpicking this a good article       igor     great article please consider to include httpmytaskhelpercom in your review       brand niemann     i think i have always been a data scientist as coined by jeff hammerbacher in facebook 2007 combining data analyst  research scientist httptwittercombniemannsrstatus15207340783 please see my data science library in the cloud httpondemandspotfirecompubliclibraryaspxfolderusersuseevl4372public       juan moya     thanks mike one of the best articles ive ever read data are our future jf       robert young     first or most recently at least yall made up web 20  now you make up data science if you want to create new information from existing read codd  thats what relations do as to r yes it is useful but sas still rules the job listings the explosion of text data distinct from audio video etc is wholly due to kiddies such as google who didnt want to build bcnf datastores because theyre the kiddies not the data just too dense  so they build using xml to compound the insult massively redundant flat files which in turn demand vast amounts of hdd and cpu to process  and they and you pat them on the back as being oh so clever  yikes the errors in the r and stat books are such to make it obvious your authors you too have an understanding of inferential statistics the only variety of any value about as deep as the iso9000 and six sigma folks  no that isnt an attaboy       michael r bernstein     the future belongs to the companies who figure out how to collect and use data successfully google amazon facebook and linkedin have all tapped into their datastreams and made that the core of their success also important is the ability to figure out how to tap into existing sources of data rather than collecting your own       eric christensen     data is cool  data science is cool  put out the feelers and collect more data figure out what to do with it later       muhammad mudssar     good article about data and its its importance specially importance of massive unstructured data the point is how one can get benefit from unstructured massive amount of data i think by using mapreduce one can find out the hidden patterns in unstructured data i think data along with better processing techniques is the future       marc     your graph of job listings vs time displays no indication of its vertical scale  does the maximum vertical point on the graph represent 3 listings or 300000 in an article on the importance of data that leaves me wondering how much of the content is hype and how much is well thought out       alan howlett aka technontologist     i see lots of commonality with richard saul wurmans definition of information architecture not the coopted web developer version information architect 1 the individual who organizes the patterns inherent in data making the complex clear 2 a person who creates the structure or map of information which allows others to find their personal paths to knowledge 3 the emerging 21st century professional occupation addressing the needs of the age focused upon clarity human understanding and the science of the organization of information technontologist       jorn bettin     very nice article however there is still a long way to go for data products the value of data analysis and representation critically depends on access to trustworthy source data quantification of trustworthiness is one of the harder problems for example the entire financial system hinges on trust and the level of trust in financial instruments is not known to be particularly stable manufacturing and publicising statements that are designed to influence the level of trust in financial instruments is an entire industry in its own right the article would be even better if it didnt contain simple calculation errors like ram has moved from 1000mb to roughly 25gb  a price reduction of about 4000 errors like this one have a direct impact on trustworthiness      httpradaroreillycommikel mike loukides     ouch  that arithmetic error really hurts thanks for pointing it outits been corrected the problem of trust is interesting  it depends to a large extent on the nature of the product we demand a different level of trust for financial products and that trust has obviously been shaken badly over the past two years than we do for facebook or linkedin recommendations  and youre right in finance theres a marketing industry thats designed to manufacture trust entirely aside from the quality of the data or the analysis       brian shaler     im going to cite the hell out of this article while a little scatterbrained it covers an amazingly broad array of subjects within the realm of data science the number of references  links to languages platformsframeworks tools and projects was very impressive thanks while all these hip new projects have been cropping up during the last five years were still at the beginning of this conversation im looking forward to seeing where the industry goes in the next five years and hope to play a part       brian shaler     i want to clarify on my last comment when i said all these i was not referring to all datarelated projects in general im aware that tools have been available to manipulate data for decades i probably should have phrased it more like with all these hip new projects cropping up        jessie wells     hi mike thanks for a really interesting article i think you mean that nasas data screening delayed discovery of ozone depletion as your links discuss not global warming the two physical phenomena are often confused but please dont further this problem they share the fact that their principal drivers are forms of pollution from human activities but they are not the same in their impacts or the actions needed to mitigate them recently a meteorological link was discovered whereby a the increased uvb radiation due to the depleted ozone layer does affect air circulation patterns in the antarctic but this is basically a reflection of the fact that almost any aspects of the earth system if you look hard enough      httpradaroreillycommikel mike loukides     im glad you liked the article  ive just fixed the reference to the ozone layer  thanks for pointing that out       megan     kudos for encouraging thoughtfulness about data and interdisciplinary approaches to data analysis problems  however i must make two points 1 actuarial science  statistics 2 for those commenting that this is the best article theyve read about data please allow me to introduce you to w edwards deming  httpenwikipediaorgwikiwedwardsdeming   statisticians have been thinking hard about data for many many years  lets not discard them with a flippant comment about actuaries and the false belief that anyone can run a few programs in r and correctly analyze data       g boyd     data science exists in order to usurp an individuals ooda loop without their knowledge as described by former air force pilot john boyd  of course data science is described as a sexy gig when youre bosses are control freaks it doesnt matter whether we get the image of the golden ring or the network centric system as both images represent identical ends       ben hoyle     great article in many ways data science and information engineering are synonymous both deal with a large amount of unstructured data and form conclusions inferences and predictions both can also be thought of as overlapping with ai and brain science what does the brain human fly etc do if not process lots of sensory data extremely cleverly we are reaching a stage where the great limiting factor to significant progress is our intelligent processing systems we are beginning to have the data but we dont yet have suitably developed systems to intelligently process that data both in a human and nonhuman manner       g boyd     ben hoyle first information engineering is a means to an end this end which can be referred to as social engineering or the designing of society and its participants  usurp ones observe and orient functions in their closedloop decision processes and you can then predict an individuals decide and act part of the loop as described by john boyd second of course we have or will soon have the algorithms available to process this data  what do you think intent harvesting and intent generation is about  this is facebooks play in the display advertising game with their launch of the i like feature  were talking about generating individual profiles on the feedback side of the loop such that controls can be implemented on other half of the loop loss of privacy and the simultaneous rise of data engineering is no accident  all these moves are driven by the goal of usurping ones ooda loop  do that across enough people in the public domain and guess what you have now why is oreilly et all not discussing this critical aspect of the technologies and strategies that are being pushed on to the tech community for deployment tell us its not relevant doesnt cut it       m s prasad     great knowledge filled  post and  good coverage of tehnology data science  as i understand  has been a forte of  statistics   mathematicians  for long  we converted it as a formidable tool and gave a face to understand it  better by  users something like putting  relativity theory in simple  words eg linux for dummies  information engineering is a process to extract the useful knowledge or result from a set of information  which can be data  and sometime intangibles also or perceived ones as far image data sets are concerned  being  multidimensional  has a total mathematical basis for its processing  and result  retrievals just my  thoughts i have posted this article  on cloud secuirty alliance  group in linked in thanks       torrance s     an incredibly well written article       martin king     there are many aspects to science much of it consists of the daily grind with data and the tools of science i think we need to be careful not to lose sight of the drivers of science and where much of science comes from  intuition and great ideas  after which we create experiments to test hypotheses which inevitably involve data of some kind       jewel ward     i would add to this list of aspects of data science the ability to determine the best way to migrate store  archive data as well as whether or not to keep it storage is indeed cheap and getting cheaper but given petabytes or yottabytes of data if you arent using 90 of what you are storing does it make sense to keep paying to store migrate etc the data barring legal requirements to do so think in terms of the larger scale of it  the electricity required both in generating the electricity itself  paying for use plus the machines that must be purchased and the humans who must be paid to manage the data through its lifecycle costbenefit analysis is an important component having said that this is a great article       fred beringer     excellent article and a good summary of where data is headed on the where data comes from you dont mentions the opendata movement im mentioning in my article about the future of data and predictive analytics  httpwwwfredberingercommusingsonthefutureofdataandpredictiveanalytics3  i hope this movement will play a big role in the future as there is so much benefits to leverage data from the public and private sectors another source of data you briefly mentions are the millions of sensors were going to see in our life in the next 510 years with the so called internet of things this is really getting real   httpwwwfredberingercomistheinternetofthingsreadyforprimetime  weve havent seen anything yet  fred       leo irakliotis     as i keel reading and reading the article the academic inside me keeps repeating the same question do we academics do a good or even adequate job at educating future data scientists  should we consider creating data science programs  what can we do to offer better more relevant education to individuals who may be pursuing or using data science  and who can possibly advise us about the practical realities of data science       vassilis nikolopoulos     excellent article on new data management trends traditional approaches to db and storage  analytics have to be changed in order to cope with this huge evolution on data and stream decision analysis olap bi and traditional data mining have to be updated with new rd tips       david alan christopher     fascinating article mike im a librarian and our lot faces a handful of data as well weve been writing some java and ruby code lately for inhouse data analysis and even some basic segmentation of our huge inventory we often need to pull content from external public websites usually government and npos which dont have any form of exportable data formats weve started using a tool called feedity httpfeeditycom for that purpose so far its worked out pretty well as weve been able to scrape raw data as structured information from hundreds of public sources i bet this space will only grow as data becomes more and more important for organizations worldwide       ellen oneal     this stuff fascinates me i love the examples of facebook linkedin and amazon using patterns to suggest other relationships and cross sell another example that comes to mind is pandora a friend of mine wrote an article that i think may be interesting to fellow readers httpinfolivelogicnetcustomerintelligenceprojectsuccessbid47060pandorasjarandtheartofthecrosssell  thanks for the post im excited to see the future of predictive analytics as my company calls it      httpwwwcaseycheshirecom casey cheshire     amazing im looking at the future thank you for teaching and sharing       tim h     great article how does a young guy with strong communications skills experience in statistics computing math and data get into this field suggestions      httpradaroreillycommikel mike loukides     theres been a good discussion on quora on how to become a data scientist httpwwwquoracomhowdoibecomeadatascientist with the skills you list it  sounds like youre a good part of the way there already mike      httpaboutmesteveardire steve ardire     great post  yes the web is full of datadriven apps but semantic datadriven apps is the future      httphalooglasicom vector     thanks for the good and quite useful article this is really an issue       booten gurg     does wikileaks apply here anyway this is government 20 at work  httpwwwnytimescom20101205world05restricthtmlhp      httpindustrialengineertoolsblogspotcom larry ieor tools     this is a great article about how getting information from data is going to be so important in the future  ive been writing about this for years  i love how data science is really taking on a life of its own now      httpwwwadaptiveprocesscom max j pucher  chief architect isis papyrus software     mike great research on a relevant subject let me however add that much of the data that is collected is irrelevant cddb is a great success because their data model is simple and the data are really very limited a few million rows filtering the relevant stuff is not easy and mostly an intuitive human skill as long as the model can be grasped statistical processing does however not replicate reality but is always built on a model illusion dont forget that all models are wrong but some are useful einstein further it depends how the data is collected how it is timed how accurate it is how it is filtered which questions were asked or points that were measured and a few more elements that rely on model assumption statistics further only produce correlation but not causation humans tend to misinterpret many effects as causes because the effect can be seen while the cause doesnt exist as a singular event but is a complex web if feeding stimuli that need a complex web of receptive context to actually make something happen ie bringing a pot of water to boil is not caused by switching on the stove think of all the other causal elements that are needed including air pressure and saline content all human activity cannot be causally interpreted because social activity must be seen as complex adaptive systems that undergo continuous change that is hardly ever reflected in the data model and processing which is why managing a business with bpm workflows and predictive analytics is for idiots who dont understand nature and science they look for predictability where there is none the models of global warming and climate change are complete rubbish and so will be many of the data models that try to make sense of all the random data collected yes some of it will be useful as an aha moment but it certainly wont predict the future or allow us to control things better and if that isnt possible why bother i wont even go into the already mentioned issues of privacy and misuse of the collected data by governments and big business      httpattorneydirectoryofamericacom attorney     while data science is incredibly beneficial and helping to improve the standard of living of humanity im not so sure that i go so far as to agree with hal varian that statistics is the next sexy job thats a bit of a stretch important absolutely sexy well great post by the way jim      httpwwwrevitolstretchmarkcreamcom revitol     a very interesting and thorough article i do feel a little uneasy though reading about the ability to extract all the types of information from raw data it looks like the big companies such as google may know a little bit too much about us       rissy     very interesting posti get a lot of information and insights herei just stumbled here in your blog and thanks a lot for this great postd      httpwwwardalahmetcom ahmet ardal     thanks for this excellent article it really encouraged and motivated me a lot as a newbie data scientist       none     i like this information thank you       wfk3     good article does it seem to anyone else that we are on our way toward creating a new reality with all this data the data may soon be more real than the real world phenomena it describes data is still conventionally seen as something than describes something else and so not the atomic thing itself but that may change so that the data itself is the atomic thing it need not describe anything but exist for its own sake          featured video  data science where are we going  dj patil the us governments first chief data scientist looks at the future of data science at strata  hadoop world 2015 in san jose  get the data newsletter    stay informed receive weekly insight from industry insiders     featured download  download the free report  more free reports      recent posts    ghosts in the machines    connected play    four short links 13 may 2015    apple watch and the skin as interface    topic modeling for the newbie    most recently discussed    archives     archives by month  may 2015  april 2015  march 2015  february 2015  january 2015  december 2014  november 2014  october 2014  september 2014  august 2014  july 2014  june 2014  may 2014  april 2014  march 2014  february 2014  january 2014  december 2013  november 2013  october 2013  september 2013  august 2013  july 2013  june 2013  may 2013  april 2013  march 2013  february 2013  january 2013  december 2012  november 2012  october 2012  september 2012  august 2012  july 2012  june 2012  may 2012  april 2012  march 2012  february 2012  january 2012  december 2011  november 2011  october 2011  september 2011  august 2011  july 2011  june 2011  may 2011  april 2011  march 2011  february 2011  january 2011  december 2010  november 2010  october 2010  september 2010  august 2010  july 2010  june 2010  may 2010  april 2010  march 2010  february 2010  january 2010  december 2009  november 2009  october 2009  september 2009  august 2009  july 2009  june 2009  may 2009  april 2009  march 2009  february 2009  january 2009  december 2008  november 2008  october 2008  september 2008  august 2008  july 2008  june 2008  may 2008  april 2008  march 2008  february 2008  january 2008  december 2007  november 2007  october 2007  september 2007  august 2007  july 2007  june 2007  may 2007  april 2007  march 2007  february 2007  january 2007  december 2006  november 2006  october 2006  september 2006  august 2006  july 2006  june 2006  may 2006  april 2006  march 2006  february 2006  january 2006  december 2005  november 2005  october 2005  september 2005  august 2005  july 2005  june 2005  may 2005  april 2005  march 2005        archives by topic  data  design  emerging tech  iot  programming  web ops  performance  web platform  divinput typesubmit valueview div         archives by author  a sinan unur  aaron sumner  adam duvander  adam flaherty  adam messinger  adam witwer  adrian mendoza  alasdair allan  alex bordei  alex bowyer  alex iskold  alexander macgillivray  alice zheng  alistair croll  allen downey  allen noren  allison randal  ally macdonald  alois reitbauer  alysa hutnik  amelia bellamyroyds  amr awadallah  amy heineike  amy jollymore  amy unruh  anant jhingran  andreas antonopoulos  andrew collette  andrew odewahn  andrew savikas  andrew shafer  andrew t baker  andy fitzgerald  andy kirk  andy konwinski  andy oram  angela rufino  ann spencer  ann waldo  anna smith  anne gentle  anni ylagan  ari gesher  aria haghighi  ariya hidayat  arnold robbins  artur bergman  arun gupta  audrey watters  avi bryant  barb edson  barbara bermes  baron schwartz  barry devlin  barry oreilly  beau cronin  ben christensen  ben evans  ben henick  ben lorica  benjamin hindman  bill higgins  bill lubanovic  bill mccoy  bonnie feldman  bradley voytek  brady forrest  brandon satrom  brett mclaughlin  brett sandusky  brett sheppard  brian ahier  brian anderson  brian boyer  brian d foy  brian dalessandro  brian foster  brian jepson  brian kardell  brian macdonald  brian oleary  brian sawyer  bruce stewart  carin meier  carl hewitt  carl malamud  cathy oneil  chao ray feng  chiuki chan  chris cornutt  chris meade  chris vander mey  chris wiggins  christine perey  ciara byrne  cliff miller  colt mcanlis  cornelia levybencheton  cory doctorow  courtney nash  dale dougherty  dan saffer  danese cooper  darren barefoot  dave himrod  dave mcclure  dave zwieback  david beyer  david cranor  david elfi  david leinweber  david recordon  david sims  david stephenson  dc denison  deni auclair  derek jacoby  dinesh subhraveti  dino esposito  dj patil  doug finke  doug hill  dr venkat subramaniam  drew daraabrams  duncan ross  dusty phillips  dw wheeler  dylan field  ea vander veer  edd dumbill  edie freedman  eli goodman  elisabeth robson  elizabeth corcoran  ellen friedman  elliott hauser  elliotte rusty harold  emma jane westby  eoin purcell  eric redmond  eric ries  ezra haber glenn  faye williams  federico castanedo  federico lucifredi  fred trotter  fred van den bosch  gabe zichermann  gavin starks  george reese  gilad rosner  glen martin  greg whisenant  gretchen giles  gustavo franco  gwen shapira  hadley wickham  hari k gottipati  heather mccormack  hew wolff  howard wen  hugh mcguire  imran ali  j paul reed  james bridle  james turner  janaya williams  jane sarasohnkahn  jason grigsby  jason strimpel  jay kreps  jay mcgavren  jayant shekar  jeevan padiyar  jeff gothelf  jeff needham  jeffrey carr  jeffrey carr  jenn webb  jennifer pahlka  jeremy freeman  jeremy howard  jesper andersen  jesse anderson  jesse robbins  jessica mckellar  jesus m gonzalezbarahona  jez humble  jim scott  jim stogdill  jimmy guterman  jo prichard  joanne molesky  jodee rich  joe procopio  johan bergstrom  john allspaw  john battelle  john boxall  john feland  john foreman  john geraci  john grahamcumming  john king  john labovitz  john lindquist  john myles white  john piekos  john russell  john warren  john wilbanks  jon bruner  jon callas  jon cowie  jon roberts  jon spinney  jon udell  jonas luster  jonathan alexander  jonathan reichental phd  jonathon thurman  jono bacon  joseph hellerstein  joseph j esposito  josh lockhart  josh simmons  joshuamichele ross  joy beatty  jud valeski  julie steele  justin dombrowski  justin hall  justo hidalgo  karl fogel  kassia krozser  kat meyer  kate eltham  kate pullinger  kathryn barrett  kathy sierra  kathy walrath  katie cunningham  katie miller  keith comito  keith fahlgren  ken yarmosh  kevin shockey  kevin sitto  kevin smokler  khaled el emam  kieren jameslubin  kipp bradford  kit seeborg  kiyoto tamura  kmatsudaira  kurt cagle  lara swanson  laura dawson  laura klein  laurel ruma  laurie petrycki  leigh dodds  liliana bounegru  linda stone  lisa mann  liza daly  lorna jane mitchell  lorne lantz  luciano ramalho  lucy gray  lukas biewald  mac slocum  madhusudhan konda  mandi walls  manish lachwani  marc goodman  marc hedlund  marie beaugureau  marie bjerede  mark drapeau  mark grover  mark jeftovic  mark lutz  mark nelson  mark pacelle  mark sigal  marko gargenta  martin kalin  martin kleppmann  mary treseler  matt garrish  matt makai  matt neuburg  matt wood  matthew burton  matthew gast  matthew mccullough  matthew russell  matthew russell  max kanatalexander  max shron  meghan athavale  meghan blanchette  mehdi daoudi  michael dehaan  michael driscoll  michael ferrari  michael freeman  michael gold  michael hunger  michael jon jensen  michael lopp  michael mcmillan  michael scroggins  mike amundsen  mike barlow  mike hendrickson  mike honda  mike loukides  mike petrovich  mike shatzkin  mitchell hashimoto  naomi robbins  nat torkington  nate osit  nathan jepson  neal ford  nicholas tollervey  nick bilton  nick farina  nick kolegraff  nick lombardi  nick ruffilo  nicolas garcia belmonte  nikolaj nyholm  oreilly radar  oreilly strata  ohad samet  osman rashid  pablo francisco arrieta gomez  paco nathan  pamela samuelson  paris buttfieldaddison  patrick mulder  patrick reynolds  paul spinrad  pete hodgson  pete warden  peter arijs  peter bennett  peter cooper  peter krautzberger  peter laflin  peter lewis  peter meyers  philip guo  philipp janert  q ethan mccallum  quinn norton  rachel roumeliotis  rael dornfest  raffael marty  rajat bhargava  ramez naam  randy bias  raven zachary  ray digiacomo jr  renee diresta  reynold xin  richard cook  richard dallaway  richard reese  richard warburton  rob tucker  robbie allen  robert kaye  robert passarella  roberta cairney  roger chen  roger magoulas  rogier docwilco mulhuijzen  ron miller  roseanne fallin  rune madsen  russell jt dyer  ryan bethencourt  ryan neufeld  ryan stewart  sam newman  samuel mullen  sanders kleinfeld  sara peyton  sara winge  sarah milstein  sarah novotny  scott jenson  scott murray  scott rich  scott ruthfield  sean mcgregor  sean o sullivan  sebastien pierre  semmy purewal  seth ladd  shahid shah  shahin farshchi  shai almog  shannon cutt  shyam seshadri  silona bonewald  simon chan  simon phipps  simon st laurent  simon wardley  spencer critchley  stefan thies  stephen elston  stephen ogrady  stephen ogrady  steve souders  steven citronpousty  steven shorrock  stoyan stefanov  suzanne axtell  tara hunt  terrence dorsey  terry jones  tim anderson  tim busbice  tim darling  tim oreilly  timothy m obrien  timothy mcgovern  tish shute  toby inkster  todd sattersten  tom eisenmann  tom steinberg  tony quartarolo  trisha gee  troy topnik  tyler bell  valeri karpov  vandad nahvandipoor  vanessa fox  varun nagaraj  will cukierski  william mougayar  william oconnor  zigurd mednieks  divinput typesubmit valueview div      contact us  radar managing editor  jenn webb         sign up today to receive special discounts product alerts and news from oreilly            privacy policy   view sample newsletter    twitter youtube slideshare facebook google rss view all rss feeds       2015 oreilly media inc  707 8277019 800 8898969  all trademarks and registered trademarks appearing on oreillycom are the property of their respective owners      about oreilly  about oreilly radar radar contributors academic solutions jobs contacts corporate information press room privacy policy terms of service writing for oreilly editorial independence     community  authors community  featured users forums membership newsletters oreilly answers rss feeds oreilly chimera beta     partner sites  makezinecom makerfairecom craftzinecom igniteshowcom paypal developer zone oreilly insights on forbescom     shop oreilly  customer service contact us shipping information ordering  payment affiliate program the oreilly guarantee          close  get the oreilly data newsletter  stay informed receive weekly insight from industry insiders            '
p5
aS'      about what is data science research academics   overview  programs news contact us        data science at nyu            about what is data science research academics   overview  programs news contact us     data science at nyu                    what is data science                   what is it   applications   nyu projects   the profession      what is data science  there is much debate among scholars and practitioners about what data science is and what it isnt does it deal only with big data what constitutes big data is data science really that new how is it different from statistics and analytics      one way to consider data science is as an evolutionary step in interdisciplinary fields like business analysis that incorporate computer science modeling statistics analytics and mathematics   at its core data science involves using automated methods to analyze massive amounts of data and to extract knowledge from them with such automated methods turning up everywhere from genomics to highenergy physics data science is helping to create new branches of science and influencing areas of social science and the humanities the trend is expected to accelerate in the coming years as data from mobile sensors sophisticated instruments the web and more grows in academic research we will see an increasingly large number of traditional disciplines spawning new subdisciplines with the adjective computational or quantitative in front of them in industry we will see data science transforming everything from healthcare to media      50x   in 2020 the world will generate 50 times the amount of data than in 2011  source emccom           data science         applications        computer science        mathematical statistics                 datadriven discovery  what data science means for research  in virtually all areas of intellectual inquiry data science offers a powerful new approach to making discoveries by combining aspects of statistics computer science applied mathematics and visualization data science can turn the vast amounts of data the digital age generates into new insights and new knowledge  click on the icons to the left to see how social scientists medical researchers and many others are using data science to advance their fields    measuring happiness  social science  facebook and twitter collect in hours what traditional methods take sociologists months or even years to gather hedonometer a tool created by university of vermont researchers is putting that social data to use it pulls in 50 million tweets each day and matches those tweets against a database of words assigned a happiness value the higher the hedonometer number on a particular day the happier the collective mood of twitter users and presumably a wider group of people some findings are predictable the day of the boston bombings was the worlds saddest day in five years other findings are surprising twitter users happiness increases the further they move from home  source washington post    global pricing  economics  how much higher do products labeled as green or organic sell for around the globe what drives certain goods to stay the same price in the face of changing economic conditions how much do prices adjust in a country when its exchange rate changes these are among the questions mits billion prices project aims to answer the project collects prices from hundreds of online retailers around the world on a daily basis for economic research  source the billion prices project at mit    designing new materials  engineering  researchers at columbia university are attempting to reverse the model of scientists coming up with new materials and then finding applications for them their method builds on dna research from nyu and employs aspects of data science to help engineers design nanomaterials with particular properties by harnessing a huge and growing body of high throughput experimentation data the researchers approach could replace timeconsuming and expensive trialanderror design methods engineers traditionally use to create new materials accelerating the timetomarket for new products  source engineeringcolumbiaedu    smarter document mining  law  legal professionals and scholars have relied on digitized legal documents briefs memos and other records to conduct their research for many years proprietary platforms however can be costly for independent lawyers and small firms and search methods are limited enter a startup like briefmine out of san francisco which is using data science to provide a more affordable more efficient alternative within its growing repository of documents briefmines technology identifies data points conducts trend analysis and develops scoring frameworks based on relevance and natural language search  source techco    a new corporate asset  business  from production floors to facebook pages every point of a companys operations now generates data according to mckinsey quarterly big data may well become a new type of corporate asset that will cut across business units and function much as a powerful brand does representing a key basis for competition to get the most out of that asset companies are turning to data scientists to collect integrate and analyze data schools like nyu have developed degree programs to fill the growing gap between the number of trained data scientists and the needs of businesses  source mckinsey quarterly    layering datasets  medicine  joel dudley of mt sinai offered an example at databeat 2013 of how data science can help discover diseases that researchers dont even know to look for mt sinai has a unique resource clinical data from 25000 patients and their genomic data researchers could crossreference the two types of data and isolate smaller populations of people who may share traits for instance a group who are diabetic may be prone to one particular disease and another group of diabetic patients prone to another disease this might illuminate a new form of diabetes and lead to more personalized treatment  source datascienceberkeley    seeing exoplanets  sciences  astronomical instruments such as optical and spacebased telescopes collect huge amounts of information deblurring that optical data to find exoplanets requires new ways to represent images one of the most efficient deblurring methods comes from recent advances in applied mathematics but efficiently computing these sparse representations requires new optimization methods involving statistical inference in complex bayesian models with data science we can bring techniques from different disciplines together aiding the hunt for planets outside our solar system  source nyu report on the initiative in data science and statistics                 data  context  drawing insight from a piece of data involves understanding how it fits into the larger picture of an organization explains ibms jeff jonas distinguished engineer and chief scientist for ibm entity analytics business environments arent the only ones that require context context is a necessity for any attempt to know more by examining data                   about  the data science initiative at new york university is a universitywide effort to establish the countrys leading data science training and research facilities at nyu it was launched to help meet the worlds demand for researchers and professionals skilled in developing and utilizing automated methods of analyzing data the initiative is especially focused on harnessing the potential power of big data to transform areas ranging from healthcare to business to government data science overlaps traditionally strong disciplines at nyu such as mathematics statistics and computer science it also stands to impact disciplines in which nyus schools and departments are actively engaged such as economics law and sociology       where  new york universitywashington square campus  phone  2129983401       questions or comments     thank you well be in touch shortly    oops looks like something went wrong ensure you have entered all details correctly                               about research academics news     copyright  2013  new york university              '
p6
aS'                       home data science services blog about               home  what is data science   what is data science  theories behind data science if youd like to perform data science there are several theories and principles that you need to understand  and once you understand these theories and principles it will allow you to learn a certain set of practices and step by step skills that data scientists do  if you dont understand these theories and principles then you wont be able to understand the practices and skills  so first let me teach you a few theories and principles that are involved and once you understand the theoretical elements then i can teach you a simple stepbystep method for doing data science database theory firstly lets talk about database theory  database theory is about organising data and organising it in a way that makes storing and retrieving it efficient  data can be categorised into objects objects can be put into collections and objects and collections can have relationships between each other and themselves  the one thing you need to know about this theory is that they way you organise your data will impact the effort required to get answers from it agile manifesto now lets talk about the agile manifesto  the agile manifesto is a set of principles that ensures high quality outputs in environments subject to high levels of change and ambiguity  agile methods overcome rapid changes and ambiguity through adopting an iterative development process  it utilises self managed teams and those that are passionate about technological advancements are drawn to it like scientists to big bang theory  the agile manifesto looks to remove all cultural barriers between developer client and end user and focuses on using the latest technology to making things simple but not simpler  the one thing you need to know about this set of principles is that all things change and the longer you take to test your solution in the live environment the higher the risk of failure spiral dynamics the last theory id like to touch on is spiral dynamics theory  spiral dynamics is a theory of human development and behaviour and explains why humans do what we do  it explains the psychology behind why we get out of bed in the morning  why we feel compelled to create things and why we seek to better ourselves and better serve our loved ones  the theory talks about two mental states one of facts and one of values  facts are what we believe  our beliefs are based on the knowledge we currently have and the environment we are currently in  values are what we desire  our desires are driven by our intentions andor concerns which are also based on the knowledge we currently have and the environment we are currently in  the one thing you need to know about this theory is that our facts and our desires come from what data is presented to us data scientists data scientists perform data science  they use technology and skills to increase awareness clarity and direction for those working with data  the data scientist role is here to accommodate the rapid changes that occur in our modern day environment and are bestowed the task of minimising the disruption that technology and data is having on the way we work play and learn  data scientists dont just present data data scientists present data with an intelligence awareness of the consequences of presenting that data how to do data science the three components involved in data science are organising packaging and delivering data the opd of data  organising is where the physical location and structure of the data is planned and executed  packaging is where the prototypes are build the statistics is performed and the visualisation is created  delivering is where the story gets told and the value is obtained  however what separates data science from all other existing roles is that they also need to have a continual awareness of what how who and why  a data scientist needs to know what will be the output of the data science process and have a clear vision of this output  a data scientist needs to have a clearly defined plan on how will this output be achieved within the restraints of available resources and time  a data scientist needs to deeply understand who the people are that will be involved in creating the output  and most of all the data scientist must know why there is a motivation behind attempting to manifest the creative visualisation the 3 step opd data science process step 1 organise data organising data involves the physical storage and format of data and incorporated best practices in data management step 2 package data  packaging data involves logically manipulating and joining the underlying raw data into a new representation and package step 3 deliver data delivering data involves ensuring that the message the data has is being accessed by those that need to hear it plus at all steps have answers to these questions  what is being created  how will it be created  who will be involved in creating it  why is it to be created the data science model data science in action data science in action it is simply about moving people andor systems between current and new technologies and between beginner and expert skills step 1 organising data organising data involves moving people and systems from current to new left to right and from beginner to expert top to bottom  advancing technologies and skills is the essence of innovation step 2 packaging data packaging data is the reverse of organising data and involves moving people and systems from new to current right to left and from expert to beginner bottom to top  this is the art of making things simple but not simpler step 3 delivering data delivering data is enabling the movement from one view to another enabling a beginner to become an expert enabling current technology to seem new enabling expert data to be understood by beginners and enabling new technology to seem like it has be a part of your life since you were born  this is transformational education tweet          links list  home data science services blog about    subscribe     full name      email address      enter word verification in box below             recent news no news found   follow us   facebook  twitter  linkedin        copyright  2011 data scientists pty ltd abn 45134581089 acn 134581089  home contact terms of service privacy       '
p7
aS'       rarefied talent in big data technology and analytics     post jobs  employer login              home    data science jobs  analytics     data technology jobs     about datajobscom     big data knowledge repo     what is data science  what is analytics what is a data scientist    posted by frank lo      we have lots of data  now what  how can we unlock valuable insight from our data    data science is deep knowledge discovery through data inference and exploration this discipline often involves using mathematic and algorithmic techniques to solve some of the most analytically complex business problems leveraging troves of raw information to figure out hidden insight that lies beneath the surface it centers around evidencebased analytical rigor and building robust decision capabilities  ultimately data science matters because it enables companies to operate and strategize more intelligently  it is all about adding substantial enterprise value by learning from data     the variety of projects that a data scientist may be engaged in is incredibly broad here are few examples   tactical optimization improvement of marketing campaigns business processes etc  predictive analytics anticipate future demand future events etc  nuanced learning eg developing deep understanding of consumer behavior  recommendation engines eg amazon product recs netflix movie recs  automated decision engines eg automated fraud detection and even selfdriving cars   the objectives of these types of initiatives may be clear but the problems require extensive quantitative expertise to solve they may require building predictive models attribution models segmentation models heuristics for deep patterndiscovery in data etc  this commands having exhaustive knowledge of all sorts of machinelearning algorithms and sharp technical ability as you might guess these are not the easiest skills to pick up   what is data science  the requisite skill set  data science is multidisciplinary the skill set of a data scientist lies at the intersection of 3 main competencies      mathematics expertise   at the heart of deriving insight from data is the ability to view the data through a quantitative lens there are textures patterns dimensions and correlations in data that can be expressed numerically and discovering inference from data becomes a brain teaser of mathematical techniques solutions to many business problems often involve building analytic models that are deeply grounded in the hard math theory and being able to understand how models work is as important as knowing the process to build them  danger of building without knowing the math    beware of people who know just enough to build a model but dont fully understand the mechanics of how the model works this can easily end up with misuse of algorithms misinterpretation of results and misleading insight which can steer a business in the wrong direction   also a big misconception is that data science all about statistics while statistics are important it is not the only type of mathematics that should be wellunderstood by a data scientist first there are two main branches of statistics classical statistics and bayesian statistics  when most people refer to stats they are generally referring to classical stats  but knowledge of both types is very helpful furthermore many inferential techniques and machine learning algorithms lean heavily on knowledge of linear algebra  for example key data science processes like svd used for dimension reduction  latent variable discovery are grounded in matrix mathematics and have much less to do with classical statistics overall data scientists should have substantial breadth and depth in their knowledge of math   technology and hacking   first lets clarify on that we are not talking about hacking as in breaking into computers were referring to the techdeveloper subculture meaning of hacking ie creativity and ingenuity in using technical skills to build things and find clever solutions to problems  why is hacking ability important because data scientists absolutely need to leverage technology in order to wrangle enormous data sets and work with complex algorithms and it requires using tools far more sophisticated than excel examples of such tools are sql  sas  and r  all of which require technicalcoding ability with these highperformance tools a true hacker is a technical ninja able to use ingenious problem solving ability to achieve mastery in data exploration  piecing together unstructured information and teasing out golden nuggets of insight  another way to define a hacker is as a solid algorithmic thinker that is having the ability to break down messy problems and recompose them in ways that are solvable this is critical for good data science especially since data scientists work intimately within existing algorithmic frameworks and oftentimes create their own algorithms to solve complex problems clarity of thinking within deeplyabstract mental maps of data dimensions and processing capability is how challenging problems get solved   strong business acumen   it is very important to note that a data scientist is first and foremost a strategy consultant  data science teams have become invaluable resources within companies because by being able to learn from data in ways no one else can they are extraordinarily wellpositioned to figure out how to add substantial business value but this means having a keen sense of how to dissect and approach business problems becomes as important as having a keen sense of how to approach algorithmic problems ultimately the value doesnt come from numbers it comes from strategic thinking based on those numbers  additionally a core competency of data science is in using data to cogently tell a story this means no datapuking rather presenting a cohesive narrative of problem and solution using data insights as supporting pillars that lead to guidance  clearly get all the competencies right  math technology and business  and this is an incredibly potent combination there is a reason why data scientists are well paid and probably will never have to worry about job security not a bad place to be to have the rarefied talents that big companies everywhere are trying to recruit    what is a data scientist  curiosity and training   the mindset   a defining personality trait of data scientists is they are deep thinkers with intense intellectual curiosity  data science is all about being inquisitive  asking new questions making new discoveries and learning new things ask true data scientists what drives them in their job and they will not say  money   the real motivator is being able to use their creativity and ingenuity to solve hard problems and constantly indulge in their curiosity deriving insight from data is not about getting an answer it is about uncovering  truth  that lies hidden beneath the surface problem solving is not a task but rather an intellectuallystimulating journey to a solution there is passion for the work and great satisfaction in taking on challenge   training   while solid math skills are necessary there is a glaring misconception out there that you need a phd in statistics to become a legitimate data scientist that view completely misses the point that data science is multidisciplinary years of study in academia may not leave graduates with the correct set of experience and abilities to excel  ie a phd statistician may not have nimble hacking skills or strategic business intuition to complete the trifecta  as a matter of fact data science is such a relatively new and rising discipline that universities have not caught up in developing comprehensive data science degree programs  meaning that no one can really claim to have  done all the schooling  to be become a data scientist where does much of the training come from the unyielding intellectual curiosity that data scientists possess drive them to be passionate autodidacts  motivated to learn skills on their own with deep determination  read where can you find people like this    analytics and machine learning  how it ties to data science  there are a slew of terms closely related to data science that we hope to add some clarity around   what is analytics   analytics has risen quickly in popular business lingo over the past several years the term is used loosely but generally meant to describe critical thinking that is quantitative in nature technically analytics is the  science of analysis  put another way the practice of analyzing information to make decisions  is  analytics  the same thing as data science depends on context sometimes it is synonymous with the definition of data science that we have described and sometimes it represents something else a data scientist using raw data to build a predictive behavior model falls into the scope of analytics at the same time a general business user interpreting prebuilt dashboard reports eg ga  is also in the realm of analytics but does not cross into the specialized skill needed in data science analytics has come to have fairly broad meaning though at the end of the day the semantics dont matter much    what is the difference between an analyst and a data scientist     analyst  is somewhat of an ambiguous term that can represent many different types of roles marketing analyst operations analyst portfolio analyst financial analyst etc is an analyst the same as a data scientist weve discussed pretty strict canon around what is a data scientist  as an experts role with requisite talents in math technology and strategy consulting lets just say that some analysts are definitely datascientistsintraining as represented in this visual there is a place in the middle where the distinction can blur a bit  here are examples of growth from analyst to veritable data scientist   an analyst who has previously only mastered excel learns how to dive into raw warehouse data using sql and r  an analyst who previously only knew enough stats to report the results of an ab test gains the expertise to build a predictive model with latent variable analysis and crossvalidation   overall point is that moving in the direction of  data scientist  requires motivation to learn many new skills many companies have actually found success cultivating their own homegrown data scientists by giving their analysts the resources and training to take their abilities to the next level   what is machine learning   machine learning is a term that is closely tied to data science simply it means being able to train systems or algorithms to derive insight from a data set the actual types of machine learning are varied ranging from regression models to support vector machines to neural nets but it all centers around  teaching  a computer to become very good at pattern recognition examples of machine learning include   predictive models that can anticipate user behavior  clustering algorithms that mine for natural similarities between different customers  classification models that can recognize and filter out spam  recommendation engines that  learn  about preferences at an individual level  neural nets that can recognize what image patterns look like   data scientists work intimately with machine learning techniques to build algorithms that automate elements of their problemsolving it is a requisite part of the data science toolset needed to tackle some of the most complex datadriven projects   what is data munging   raw data can be unstructured and messy with information from disparate data sources and mismatched records data munging is a term to describe the important process of cleaning up data so that it is ready for data analysis and use in machine learning algorithms this requires good patternrecognition ability and clever hacking skills in order to merge and transform masses of raw information dirty data can obfuscate the  truth  hidden in the data and completely mislead an analysis thus any data scientist must be skillful and nimble at data munging in order to have accurate data for deriving insight  final word  in any organization that wants to leverage big data to gain value data science is the secret sauce but it is incredibly difficult to find experts who embody all the necessary talents  so if you manage to hire a data scientist nurture them keep them engaged and give them autonomy to be their own architects in figuring out how to add value to the business at the end of the day data science is a capability that turns information to gold and data scientists are uniquely positioned to be transformative figures within a company          tweet         post or tweet this article            read about big data       what is big data  what is data science  what is hadoop and nosql  state of big data recruiting  big data salary an inside look         experts corner       for big data specialists only    data science  math and tech  data warehousing  platforms    page coming soon           big data job market       currently in very high demand    data scientists  analytics managersdirectors  business analysts  bi developers  big data architects  nosql dbas  hadoop experts       2015 datajobscom all rights reserved         '
p8
aS''
p9
aS'        searchbusinessanalytics         search the techtarget network     signup now start my free unlimited access     login         search business analytics       searchdatamanagement  searchaws  searchcontentmanagement  searchcrm  searchoracle  searchsap  searchsqlserver       topic   predictive analytics          analytics  view all    advanced analytics  aws analytics  big data analytics  data mining  customer analytics  text analytics      bi management  view all    bi best practices  bi case studies  bi project management  bi strategy  bi team and staffing  operational bi  bi selection  selfservice and collaborative bi      bi technology  view all    integration  development  bi software  enterprise reporting  ibm bi  microsoft bi  open source bi  oracle bi  realtime bi  saas bi  sap bi      performance management  view all    cpm best practices  cpm technology  forecasting planning and budgeting      analytics  view all    advanced analytics  aws analytics  big data analytics  data mining  customer analytics  predictive analytics  text analytics      data visualization  view all    dashboards and scorecards  data mashups  data visualization software      data warehousing  view all    big data management  data modeling  data warehouse appliances  project management  data warehouse software  data architecture  hadoop      topics archive  view all     please select a category   bi management  bi technology  performance management  analytics  data visualization  data warehousing        section   get started        news  get started  evaluate  manage  problem solve  sponsored communities                essential guide    building an effective data governance framework  a comprehensive collection of articles videos and more handpicked by our editors     data scientist         posted by margaret rouse   whatiscom                  a data scientist is a job title for an employee or business intelligence bi consultant who excels at analyzing data particularly large amounts of data to help a business gain a competitive edge    from the essential guide  building an effective data governance framework     guide sections    best practices    data stewardship    problem solving    glossary    quiz        show more        sections    essential guide section youre in terms related to data governance and stewardship    more articles from this section    big data     business intelligence     data governance     data management     data profiling     data quality     data scrubbing data cleansing     data stewardship     master data management mdm      share this item with your network                          product reviews powered by it central station      splunk    vs     inetco insight       evolven    vs     extrahop       glassbeam    vs     groundwork     browse definitions alphabetically   a  b  c  d  e  f    g  h  i  j  k  l    m  n  o  p  q  r    s  t  u  v  w  x    y  z       sponsored news    national ignition facility accelerates oracle vms with flash and scaleout   netapp    five things to know about hadoop for managing unstructured data  intel   see more   vendor resources    realtime bi gives performance envelope a bigtime push  sas     tip guide data scientists dig open source tools transaction data  sybase an sap company      this content component encountered an error  glossary  data scientist is part of the   business intelligence  business analytics glossary     data and data management glossary    view all definitions   related terms    data sampling   data sampling is a statistical analysis technique used to select manipulate and analyze a representative subset of data points  see complete definition     ensemble modeling   ensemble modeling is the process of running two or more related but different analytical models and then synthesizing the results see complete definition     r programming language   the r programming language is an open source scripting language for predictive analytics and data visualization see complete definition        pro  content  find more pro content and other member only offers here         ebook  market trends tell the future of predictive analytics deployments        essential guide  building an effective data governance framework   guide sections    best practices    data stewardship    problem solving    glossary    quiz                 0 comments  oldest  newest            register or login  email   username  password  password    forgot your password   by submitting you agree to receive email from techtarget and its partners if you reside outside of the united states you consent to having your personal data transferred to and processed in the united states privacy       load more comments         forgot password   no problem submit your email address below well send you an email containing your password       email     submit        your password has been sent to         ads by google       file extensions and file formats   a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s    t  u  v  w  x  y  z      powered by      latest techtarget resources    data management      aws      content management      crm      oracle      sap      sql server             search data management      sql server 2016 azure sql data warehouse lead microsoft cloud hopes  microsoft is working on yet another computing transformation and azure sql products are central thereto but the company faces      sort through types of database management systems before you buy  the database management system lies at the center of any organizations business activities it houses the data that pumps life      with database management tools never settle  theyre the heart of it all pumping data to applications and business processes but the sheer number of products on the market         search aws      benefits of using amazon ec2 container service with docker  running docker in amazon ec2 container service allows for greater cloud portability and reduced costs we explain how to get      how aws compares to digitalocean cloud services  how does digitalocean compete with aws we dig into the iaas provider to see where it matches aws and where it has an edge over      aws cloud management smoothed by thirdparty tool  an aws shop turned to a product from an aws premier partner to collect correlate and manage the data produced by native amazon         search content management      cloud features push sharepoint 2016 hybrid scenarios  at ignite microsoft walked a fine line in pledging renewed commitment to sharepoint onpremises because much of the emphasis      merging your view of structured and unstructured data in sharepoint  companies are seeing the merits of merging structured and unstructured data in sharepoint but gaining the resulting business      dont blame sharepoint for poor sharepoint adoption  companies often blame sharepoint for poor user adoption but the reality is more complex        search crm      customer personalization brings intelligence to sales and marketing  generic messages to customers and prospects are losing their effectiveness today tailoring interactions to individuals is      contact center analytics still an uncharted frontier  analytics tools have been incorporated into various enterprise departments so whats holding contact centers back from investing     entrepreneur takes road less traveled in technologydriven business  ken kelly didnt plan on taking over his fathers company but a few classes in microsoft office paved the way to a         search oracle      oaug head sees user options issues in oracle cloud services push  in a qa oaug president melissa english discusses how oracles increasing focus on cloud computing services affects users and      oaug president collaborate 2015 confab peaked with networking  in a qa oaug president melissa english discusses her passion for mingling with attendees at the 2015 collaborate conference and     ioug president dissects oracle conferences at collaborate 2015 event  ioug president john matelski answers questions about oracle users attending the big conferences like collaborate 15 and the         search sap      sapphire attendees take long view despite s4hana roadmap gaps  sap sapphire attendees expressed longterm confidence in the companys s4hana platform but also said the transition will not be     in a hybrid world sap support services face challenges  the increase in mobile and cloud apps means companies are reevaluating their approach to sap support experts discuss current      sap sapphire now 2015 special conference coverage  news analysis and video from sap sapphire now taking place may 57 in orlando        search sql server      sql server 2016 preview announced for summer 2015  microsoft ceo satya nadella announced the sql server 2016 preview for this summer its new features model the ethos of mobile      will the r language benefit from microsoft acquisition  microsofts recent acquisition of revolution analytics could go a long way in solidifying the r languages hold on analytical      builtin tools for monitoring and optimizing olap cubes  optimizing online analytical processing performance is critical fortunately tools are available to help monitor and improve how               about us  contact us  privacy policy  videos  photo stories  guides    advertisers  business partners  media kit  corporate site  experts    reprints  archive  site map  events  eproducts      all rights reserved  copyright 2010  2015  techtarget       iframe srcwwwgoogletagmanagercomnshtmlidgtm5cv3pdheight0 width0 styledisplaynonevisibilityhiddeniframe       div styledisplayinlineimg height1 width1 styleborderstylenone alt srchttpgoogleadsgdoubleclicknetpageadviewthroughconversion1070110249value0labelrrsgcow4tgmqqayigmguidonscript0div div styledisplayinlineimg height1 width1 styleborderstylenone alt srchttpgoogleadsgdoubleclicknetpageadviewthroughconversion1072226410value0labelx3pciql1gmq6scjwmguidonscript0div       close    '
p10
a.